<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Mood Mirror: Let AI Decide How You Feel About Makeup — Absurdly Intelligent</title>
  <link rel="stylesheet" href="../../assets/style.css" />
</head>

<body>

  <!-- Top Bar -->
  <header class="topbar">
    <div class="wrap topbar-inner">
      <a class="brand" href="../../">
        <span class="brand-dot"></span>
        <span class="brand-title">Absurdly Intelligent</span>
        <span class="brand-sub"></span>
      </a>
    </div>
  </header>

  <article class="wrap article">

    <a class="breadcrumb" href="../../">← Back to posts</a>

    <h1>Mood Mirror: let AI decide what you like.</h1>
    <div class="date">February 4, 2026 • 3 min read • Category: beauty tech</div>

    <div class="divider"></div>

    <!-- IMAGE 1 -->
    <!-- img1.png: Woman with emotion analysis overlay -->
    <img class="img" src="img1.png" alt="Facial emotion analysis overlay showing joy and expressiveness" loading="lazy" />

    <div class="content">

      <p>
        Choosing makeup can be hard. Apparently, the solution is to stop choosing altogether and let a webcam do it for you.
        Mood Mirror is an AI-powered virtual try-on system that doesn’t just show you what lipstick or hair color looks like —
        it watches your face while you react and quietly decides what you *actually* like. Smiled a little more? Eyebrows
        raised? Micro-expression detected? Congratulations, the algorithm has opinions about your taste now.
      </p>

      <!-- IMAGE 2 -->
      <!-- img2.png: L’Oréal Mood Mirror interface -->
      <img class="img" src="img2.png" alt="Mood Mirror interface showing top and bottom makeup looks with emotion metrics" loading="lazy" />

      <p>
        Here’s how it works: you sit in front of your laptop, turn on the webcam, and start trying on virtual makeup.
        Behind the scenes, facial-recognition and emotion-detection software tracks things like smiles, surprise, eye
        widening, and head tilts. Mood Mirror then ranks the looks based on how positively your face reacted — not how you
        *said* you felt, but how your muscles betrayed you. It’s less “What do you think?” and more “Your face already
        answered.”
      </p>

      <p>
        This isn’t really about helping indecisive shoppers (yet). Mood Mirror is currently used inside L’Oréal’s research
        labs, where volunteers test products while researchers analyze emotional data instead of surveys or polite lies.
        It’s been recognized at CES and even won an Innovation Award, which makes sense — it perfectly represents where
        things are headed. First we let AI recommend products. Then we let it observe our reactions. Eventually, it just
        skips the middle step and tells us what we like before we know it ourselves. If you want the official case study
        behind this mood-reading mirror, it lives here:
        <a href="https://www.roro.io/our-work/loreal" target="_blank" style="color:var(--accent); text-decoration:none;">
          roro.io/our-work/loreal
        </a>
      </p>

    </div>

  </article>

  <footer class="footer">
    <div class="wrap">
      © <span id="year"></span> Absurdly Intelligent
    </div>
  </footer>

  <script>
    document.getElementById("year").textContent = new Date().getFullYear();
  </script>

</body>
</html>
